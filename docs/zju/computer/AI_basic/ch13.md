# 13 预训练 —— 微调和多模态模型

<!-- !!! tip "说明"

    本文档正在更新中…… -->

!!! info "说明"

    本文档仅涉及部分内容，仅可用于复习重点知识

## 13.1 私人助手定制

### 13.1.2 微调大语言模型

在通用的预训练模型基础上用特定的数据进行微调，以完成特定的下游任务，是目前应用预训练大模型的主要方式。这种预训练 —— 微调模式不但可以将预训练模型学到的知识进行迁移，而是可以进一步学到专业的知识，以完成特定的下游任务。不仅如此微调还是有监督的学习，一般会使用高质量的数据集，因此训练速度很快，一般只需几轮训练就能完成

微调方式分类：

1. 全微调（Full Fine-Tuning）：基础模型的所有参数都参与微调，适用于有全新的足够大的数据。微调时需要对原生模型的知识进行重构以适应新的环境，比如从英文语境转到中文语境
2. 部分微调（Partial Fine-Tuning）：冻结基础模型部分层的参数，调整非冻结参数
3. 高效参数微调（Parameter Efficient Fine-Tuning，PEFT）：这是目前最常用的微调方式，它通过微调少量参数来达到接近全量微调的效果。常见的 PEFT 技术有 LoRA、Adapter Tuning、 Prefix Tuning、 Prompt Tuning
4. 提示词微调（Prompt Tuning）：通过精心制作的提示词模板和对应的输出实现模型的微调，而不对基础模型的任何参数进行更新，只更新 embedding 参数
5. RLHF（Reinforcement Learning from Human Feedback）：使用强化学习的方式直接优化带有人类反馈的语言模型，实现与人类价值观的对齐

## 13.2 多模态大语言模型

多模态大型语言模型（Multi Modal Large Language Model, MLLM）是当前人工智能发展的重要方向

一个典型的 MLLM 可以抽象为 3 个模块

1. 预训练的模态编码器
2. 预训练的大型语言模型（LLM）
3. 连接它们的模态接口