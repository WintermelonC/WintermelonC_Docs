# 4 The Medium Access Control Sublayer

!!! tip "说明"

    本文档正在更新中……

!!! info "说明"

    本文档仅涉及部分内容，仅可用于复习重点知识

在广播信道中，由于多个设备共享同一介质，一个根本性的问题随之产生：当多个设备都想同时发送数据时，如何协调和仲裁，以决定哪个设备可以使用信道？这就是所谓的竞争问题。如果不加以控制，会导致数据冲突，使得所有发送都失败

为了解决这个关键问题，引入了 **MAC**（medium access control，介质访问控制）子层。它是数据链路层的一部分，专门负责制定规则和协议，以决定在广播信道上谁下一个发送

## 1 The Channel Allocation Problem

- static channel allocation

以 FDMA 为例，它预先将总带宽划分成固定数量的、互不重叠的子频带，并永久或长期地分配给每个用户。这种方式实现简单，能避免用户间的干扰

但是缺乏灵活性，效率低下。当用户数量动态变化或流量具有突发性时，问题尤为突出。突发性流量意味着用户可能在短时间内需要高速传输，然后长时间静默；资源浪费。分配给静止用户的信道在空闲时无法被其他需要的用户使用，导致宝贵的带宽资源被浪费。这在数据通信这种典型的高突发性场景中效率极低

- dynamic channel allocation

不进行固定的预先分配，而是按需动态地将信道分配给有数据要发送的用户

通过 statistical multiplexing（统计复用）来共享信道。它利用了这样一个统计事实：并非所有用户都会在同一时刻需要全速传输。因此，系统可以为大量用户服务，而无需为每个用户预留专用带宽，从而显著提高了信道利用率

### 1.1 Static Channel Allocation

为了分析静态信道分配性能不佳的原因，我们将借助一些简单的排队论计算

#### 1.1.1 Preliminary Queueing Theory

容量 $C$：指系统（在这里可以理解为共享信道）能够处理工作的最大速率（例如，总带宽或总数据处理速率）

平均需求速率 $R$：指所有用户对系统提出工作需求的平均速率（例如，所有用户平均的数据发送速率之和）

- $R < C$：系统容量在平均水平上足以满足需求。这是系统能够稳定工作的必要条件
- $R > C$：系统容量长期不足，会导致持续的拥塞、数据丢失和极长的延迟，即系统饱和

但即使满足 $R > C$，系统仍然会面临问题（如延迟、排队）。这是因为流量是随机和突发的，而不是平滑恒定的

排队（从而导致延迟）的产生源于两个固有的随机性：

1. the arrival time：数据包（或用户发送请求）到达的时间点是不可预测的
2. the service time：每个数据包所需的传输时间（或服务量）也是随机的（例如，数据包大小可变）

queueing theory 的本质是研究到达过程和服务过程的随机特性，以及这些随机性如何导致排队现象

将系统抽象为一个排队设施，用户或数据包抽象为顾客 $C_n$，定义了 3 个关键变量来数学化地描述每个顾客

1. $\tau_n$：arrival time。顾客到达队列的时刻
2. $t_n$：inter-arrival time。连续两个顾客 $C_{n-1}$ $C_n$ 到达的时间间隔
3. $x_n$：service time。为顾客提供服务所需花费的时间

整个排队系统的行为是由两个随机变量序列 $\lbrace t_n\rbrace$ $\lbrace x_n\rbrace$ 共同驱动的。为了简化模型以便于理论分析，假设所有这些随机变量是相互独立的

将具体的序列抽象为两个通用随机变量：

1. $\tilde{t}$：代表任意一个到达间隔时间的分布
2. $\tilde{x}$：代表任意一个服务时间的分布

每个随机变量都关联着一个 probability distribution function（概率分布函数，PDF）

1. $A(t) = P[\tilde{t} \leqslant t]$
2. $B(x) = P[\tilde{x} \leqslant x]$

相关的 probability density function（概率密度函数，pdf）为

1. $a(t) = \dfrac{d A(t)}{d t}$
2. $b(t) = \dfrac{dB(x)}{dx}$

与这些随机变量相关的一些重要 moments（矩）为：

1. mean inter-arrival time：$E[\tilde{t}] = \dfrac{1}{\lambda}$
2. mean service time：$E[\tilde{x}] = \dfrac{1}{\mu}$

那么 $\lambda$ 就是平均到达速率，$\mu$ 就是平均服务速率

排队论的研究按复杂度和假设条件分为三个层次：

1. elementary queueing theory：通常基于最强的简化假设
2. intermediate queueing theory：放松一些假设，考虑更一般的分布
3. advanced queueing theory：处理非常复杂或特殊的模型

不同层次理论之间的根本区别在于对到达间隔时间分布 $a(t)$ 和服务时间分布 $b(x)$ 所做的假设不同

Kendall 记号：简洁、明确地指代和研究不同类型的排队系统。$A/B/m$

- $A$：代表到达间隔时间的概率分布类型
- $B$：代表服务时间的概率分布类型
- $m$：代表系统中并行服务台（或服务员、信道）的数量。这是一个整数

$A$ $B$ 从以下符号集合中取值，这些符号指代它们所对应的分布：

1. $M$：指数分布
2. $Er$：r 阶埃尔朗分布
3. $Hr$：r 阶超指数分布
4. $D$：确定性分布
5. $G$：一般分布

最简单的模式则是 $M/M/1$

对于 $G/G/1$，定义利用率因子 $\rho = \lambda \bar{x} = \dfrac{R}{C}$，表示单个服务台处于繁忙状态的时间比例。例如 $\rho = 0.8$ 意味着服务器有 80% 的时间在工作，20% 的时间空闲

对于 $G/G/m$，$\rho = \dfrac{\lambda \bar{x}}{m} = \dfrac{R}{C}$，表示每个服务台的平均利用率或系统中繁忙服务台的期望比例。例如，$m=3, \rho=0.9$，则平均来看，约有 $3 \times 0.9 = 2.7$ 个服务台处于繁忙状态，或者说 90% 的服务台在工作

为了使系统稳定（即队列不会无限增长），必须满足：$\rho < 1$

the average time in system $T = \bar{x} + W$，$W$ 是平均等待时间（顾客在队列中等待服务所花费的时间）

> $W$ 反映了共享资源所带来的代价。正是因为资源（如信道、服务器）不是独占的，而是与其他用户（顾客）共享，才产生了排队和等待现象

!!! tip "little's result"

    $\bar{N} = \lambda T$，$\bar{N}$ 表示系统中的平均顾客总数（包括正在接受服务的和正在排队等待的）

average queue size $\bar{N}_q = \lambda W$

因此，$\bar{N} = \bar{N}_q + m\rho$

> 也就是平均客户数 = 正在接受服务的平均客户数 + 正在等待的平均客户数

当一个系统有 $k$ 个顾客时，定义此时的状态为 $E_k$，状态概率 $P_k(t) = P[N(t) = k]$ 表示在特定时刻 $t$，系统恰好有 $k$ 个顾客的概率

状态转移的动态方程：$\dfrac{dP_k(t)}{dt} = \text{在时间 } t \text{ 流入状态 } E_k \text{ 的概率流率 } - \text{在时间 } t \text{ 流出状态 } E_k \text{ 的概率流率 }$

我们考虑一个稳定的系统，当 $t \rightarrow \infty$ 时，$P_k(t)$ 会收敛到一个与初始状态无关的固定值 $p_k$。$p_k$ 表示在长时间运行下，系统中恰好有 $k$ 个顾客的时间比例。例如，$p_0 = 0.2$ 意味着从长远来看，系统有 20% 的时间是空的（没有顾客）

对于 $M/M/1$ 队列，该系统具有泊松输入，那么

$P_k(t) = \dfrac{(\lambda t)^k}{k!}e^{-\lambda t}$

计算这个分布的平均值，可以发现就是 $\bar{N}(t) = \lambda t$

- $p_k = (1 - \rho) \rho^k$
- $\bar{N} = \dfrac{\rho}{1 - \rho}$
- $T = \dfrac{1/\mu}{1 - \rho} = \dfrac{1}{\mu - \lambda}$
- $\bar{N}_q = \dfrac{\rho^2}{1 - \rho}$
- $W = \dfrac{\rho / \mu}{1 - \rho}$

<figure markdown="span">
    ![Img 1](../../../img/computer_network/ch4/network_ch4_img1.png){ width="400" }
</figure>

#### 1.1.2 The Performance of Static FDM

假设一个容量（带宽）为 $C\ bps$ 的独立信道。数据帧的到达过程是随机的（泊松到达），平均到达率为 $\lambda\ frames/sec$，帧长是可变的，平均帧长为 $\dfrac{1}{\mu}\ bit$，系统被建模为一个 $M/M/1$ 队列

- 平均服务时间 $\bar{x} = \dfrac{1}{\mu C}$
- 利用率 $\rho = \lambda \bar{x} = \dfrac{\lambda}{\mu C}$
- 平均时延 $T = \dfrac{\bar{x}}{1 - \rho} = \dfrac{1}{\mu C - \lambda}$

将信道静态地划分为 $N$ 个子信道。每个子信道的容量为 $\dfrac{C}{N}\ bps$。总的帧到达率 $\lambda$ 也被平均分配到每个子信道，因此每个子信道的到达率为 $\dfrac{\lambda}{N}$

每个子信道现在可以看作一个独立的 $M/M/1$ 队列，每个子信道的平均时延：$T = \dfrac{N}{\mu C - \lambda} = NT$

因此，在静态 FDM 中，将信道划分为 $N$ 个子信道会使平均时延增加到原来的 $N$ 倍

### 1.2 Key Assumptions of Dynamic Channel Allocation

所有动态信道分配方法都基于以下五个关键假设：

1. independent traffic（独立流量）：系统由多个（N 个）独立的站点组成。每个站点独立地生成需要传输的帧，帧的到达可能符合泊松过程。这是一个单缓冲区模型：当一个站点生成一个帧后，它进入阻塞状态，专注于处理这个帧（即尝试发送，如果失败则重发），在此期间不会生成新的帧。只有在当前帧成功发送后，它才能解除阻塞并生成下一个帧
2. single channel（单一信道）：所有站点共享同一个通信信道。所有站点在信道访问能力上是平等的，所有传输都能被所有站点接收到
3. observable collisions（可观察的冲突）：当两个或更多帧在时间上重叠传输时，就会发生冲突，导致所有涉及的帧都无法被正确接收。所有站点都能够检测到冲突的发生。检测到冲突后，相关站点知道其传输失败，并将在随后的某个时间重新尝试发送
4. continuous or slotted time（连续时间或分槽时间）：帧可以在任何时刻开始传输。这意味着传输的起始点是连续的、异步的。时间被划分为离散的、固定长度的时隙。帧传输必须在一个时隙的开始时刻进行。一个时隙的长度通常等于传输一个帧所需的时间。时隙有三种状态，空闲时隙：该时隙内没有帧传输；成功传输：该时隙内恰好有一个帧传输；冲突：该时隙内有两个或更多帧同时传输，导致冲突
5. carrier sense or no carrier sense（载波侦听或无载波侦听）：在有线信道中，使用 carrier sense，站点在发送之前，可以先侦听信道，以确定信道当前是否正被其他站点使用（即是否有载波信号）。如果侦听到信道忙，站点会推迟自己的传输，直到感知到信道空闲为止。这被称为说话前先听；在无线信道中，使用 no carrier sense，站点在发送之前无法侦听信道。站点有帧要发送时，会直接进行传输。传输完成后，通过是否收到确认等方式，才能推断出传输是否成功

## 2 Multiple Access Protocols

### 2.1 ALOHA

该协议于 1970 年代在夏威夷大学被开发，主要目的是为了解决地理上的挑战：将多个分散在夏威夷不同岛屿上的用户终端连接到位于欧胡岛檀香山的一台中央计算机

它采用了一种共享介质的通信方式：所有用户终端都使用同一个无线电频率（上行链路）向中央计算机发送数据

#### 2.1.1 Pure ALOHA

工作机制：

1. 发送：任何有数据要发送的站点都可以随时发送帧
2. 确认：中央计算机在收到帧后，会通过广播（下行链路）告知所有站点。发送站通过监听这个广播来判断自己的发送是否成功
3. 冲突处理：如果发送站没有收到成功的确认（意味着发生了冲突，发生冲突的帧会被销毁），它不会立即重发，而是等待一段随机的时间后再重新发送。这种随机退避策略是为了避免多个冲突站点在相同时间后重发，导致持续冲突

<figure markdown="span">
    ![Img 2](../../../img/computer_network/ch4/network_ch4_img2.png){ width="600" }
</figure>

<figure markdown="span">
    ![Img 3](../../../img/computer_network/ch4/network_ch4_img3.png){ width="600" }
</figure>

一个传播时间为 t 的帧能够成功传输的安全条件：在其开始传输的前一个帧时间 t 到后一个帧时间 t 内（即总共 2t 的冲突窗口内），不能有任何其他帧开始传输

!!! tip "pure ALOHA 的效率"

    效率在这里具体指：在所有发送的数据帧中，成功逃脱冲突的帧所占的比例。这个比例直接决定了信道的有效吞吐量

    定义 frame time（帧时间）为传输一个固定长度的帧所需的时间。这实际上就是帧的传输延迟

    假设网络中所有站点产生的新帧的到达过程遵循柏松分布，其平均值是每帧时间 $N$ 帧

    - 如果 $N > 1$，意味着用户试图发送帧的平均速率已经超过了信道连续成功传输帧的最大能力（即每帧时间 1 帧）。结果就是，几乎每一个帧都会发生冲突，导致吞吐量极低
    - 如果 $0 < N < 1$，为了系统能够稳定工作并获得有意义的吞吐量（即成功传输的帧速率），网络负载 $N$ 必须小于 1。在这个范围内，信道尚未饱和，有成功传输的可能

    总流量负载 $G$ 代表了信道上的总流量强度，包括新帧和因冲突而重传的旧帧。这更真实地反映了信道的实际负担

    1. $G \geqslant N$
    2. 低负载 $N \approx 0$：冲突概率低，重传帧很少，因此 $G \approx N$
    3. 高负载 $N$ 增大：冲突概率显著增加，产生大量重传帧，导致 $G > N$。这形成了一个正反馈循环：高负载 -> 多冲突 -> 更多重传 -> 负载更高

    吞吐量 $S$：每帧时间内成功传输的帧数量；传输成功概率 $P_0$：任意一个传输尝试能够成功（即不与其他传输发生冲突）的概率

    $S = GP_0$

    恰好有 $k$ 次传输尝试发生的概率 $p_k = \dfrac{G^ke^{-G}}{k!}\ \ G \sim \lambda t$

    出现零次传输尝试的概率是 $p_0 = e^{-G}$。一个帧要成功传输，必须在其前后各一个帧时间内，没有其他任何帧开始传输。在这个两倍长的时间区间内，传输尝试的平均次数自然就是 $2G$。因此，在这个关键的 $2t$ 区间内，出现零次传输尝试的概率 $P_0 = e^{-2G}$

    得到 $S = Ge^{-2G}$

    求导得到当 $G = 0.5$ 时，$S$ 最大

    <figure markdown="span">
        ![Img 4](../../../img/computer_network/ch4/network_ch4_img4.png){ width="600" }
    </figure>

#### 2.1.2 Slotted ALOHA

将连续的时间划分为离散的、长度等于一帧传输时间 t 的 **slots**（时槽）。所有站点必须同步，只能在时槽的起始时刻开始发送帧。这意味着帧的发送被对齐了

由于帧只能在时槽起点开始，一个帧如果要在当前时槽与测试帧冲突，它也必须在这个时槽的起点开始。因此，冲突只能发生在同一个时槽内。将冲突窗口从 2t 减少到了 t

!!! tip "slotted ALOHA 效率"

    成功概率 $P_0 = e^{-G}$

    $S = Ge^{-G}$

    求导得到当 $G = 1$ 时，$S$ 最大，正好是 pure ALOHA 的两倍

    ---

    成功发送一个帧总共恰好需要 $k$ 次尝试的概率 $P_k = e^{-G}(1 - e^{-G})^{k-1}$。传输次数的期望值 $E$ 是发送一个帧（直到成功为止）所需的平均尝试次数。$E = \sum\limits^{\infty}_{k=1} kP_k = e^G$

    平均尝试次数 $E$ 与网络总负载 $G$ 呈指数关系。所以一旦 $G$ 轻微增加，平均尝试次数 $E$ 就会急剧上升

    > 这种微小增加导致性能急剧下降的特性，说明了分槽 ALOHA 系统是内在不稳定的。如果没有额外的控制机制，系统在负载升高时很容易陷入冲突激增、吞吐量暴跌的恶性循环

### 2.2 Carrier Sense Multiple Access Protocols

分槽 ALOHA 的最大理论效率只有 36.8%，其根本问题在于站点的盲目性，它们在发送前不知道也不关心其他站点是否正在发送，导致大量冲突

引入新思路：在局域网等环境中，站点可以侦听信道上的信号，从而了解其他站点的活动情况。这为减少冲突提供了可能

CSMA 核心思想：先听后说。在发送数据之前，先侦听信道是否空闲

!!! tip "1-persistent CSMA"

    1. 侦听：有数据要发送的站点首先侦听信道
    2. 如果信道空闲：站点立即（以概率 1）发送它的帧。1-persistent 正是得名于此
    3. 如果信道繁忙：站点会持续等待并侦听，直到信道变为空闲，然后立即发送
    4. 冲突处理：如果发生冲突（例如，两个或多个都在等待的站点同时检测到信道空闲并立即发送），则站点等待一段随机时间（退避）后，重新开始整个过程

!!! tip "nonpersistent CSMA"

    1. 侦听：有数据要发送的站点首先侦听信道状态
    2. 如果信道空闲：站点立即发送数据
    3. 如果信道繁忙：站点不会持续等待信道空闲，而是主动等待一段随机时间，之后才重新回到步骤 1，再次侦听信道

    与 1-persistent CSMA 相比：

    - 优点：1-persistent CSMA 在信道繁忙时，多个等待的站点会在信道空闲的瞬间同时发送，导致必然的冲突。nonpersistent CSMA 通过引入随机等待，打散了这些潜在冲突站点的发送时机，从而显著降低了冲突概率。更少的冲突意味着更少的重传，从而提高了信道的有效利用率
    - 缺点：nonpersistent CSMA 的随机的等待时间增加了帧的平均延迟

!!! tip "p-persistent CSMA"

    通常用于时间被划分为离散时槽的信道。这类似于分槽 ALOHA，要求所有站点在时槽边界上同步操作

    当信道空闲时，站点不总是立即发送，也不总是完全等待，而是以一个设定的概率 p 来决定是否发送

    1. 初始侦听信道空闲：站点以概率 p 在当前时槽立即发送。同时，以概率 1 - p 推迟到下一个时槽。如果推迟了，并且在下一个时槽侦听到信道依然空闲，则重复此过程。这个过程持续下去，直到帧被发送出去或检测到信道变为繁忙，退避
    2. 初始侦听信道繁忙：站点持续侦听，直到信道变为空闲。一旦信道空闲，它并不立即行动，而是等待到下一个时槽的开始，然后应用情况 1 的算法

    如果 p = 1，退化为 1-persistent CSMA。如果 p 值很小，它的行为就接近 nonpersistent CSMA

<figure markdown="span">
    ![Img 5](../../../img/computer_network/ch4/network_ch4_img5.png){ width="600" }
</figure>

### 2.3 CSMA with Collision Detection

之前的 CSMA 协议只做到了先听后说。CSMA/CD 在此基础上增加了边说边听的能力。这意味着站点在发送数据的过程中，会持续监听信道

1. **collision detection**：站点将自己发送的信号与从信道上接收到的信号进行比较。如果两者一致，说明没有冲突，传输继续；如果两者不一致，说明有另一个站点也在发送，信号叠加发生了畸变，即检测到了冲突
2. 立即中止：一旦确认冲突发生，站点立即停止当前帧的传输。这节省了时间和带宽，因为继续传输一个注定要损坏的帧是毫无意义的

!!! quote ""

    这正是经典以太网（10BASE5, 10BASE2）所采用的核心协议。这些网络使用总线型拓扑，所有站点连接在同一根同轴电缆上，使得任何一个站点发送的信号都能被所有其他站点接收到，从而为边说边听提供了物理基础

1. transmission period（传输期）：一个站点成功获取信道并传输帧
2. 空闲期：没有站点有数据要发送
3. contention period（竞争期）：在传输结束或空闲期后，多个有数据要发送的站点开始使用 CSMA/CD 规则争夺信道使用权。这个期间可能发生冲突，并通过冲突检测和退避算法来解决

<figure markdown="span">
    ![Img 6](../../../img/computer_network/ch4/network_ch4_img6.png){ width="600" }
</figure>

那冲突检测需要多长时间？

假设网络两端有两个站点 A 和 B，它们之间的信号传播延迟为 τ

1. t0：站点 A 开始发送帧
2. t0 + τ - ε: 就在 A 发送的信号即将到达 B 的前一瞬间（ε 是一个无限小的时间量），站点 B 也开始了发送。由于 B 此时尚未感知到 A 的信号，它认为信道是空闲的
3. t0 + τ: B 立即检测到冲突（因为它发送的信号与刚到达的 A 的信号混合），并停止发送，同时发出一个强化冲突的信号（噪声脉冲）
4. t0 + 2τ - ε: 这个表明冲突发生的噪声脉冲传回到站点 A

从 A 开始发送 (t0) 到它最终检测到冲突 (t0 + 2τ - ε)，总共经历了接近 2τ 的时间

这个 2τ 的时间段被称为冲突窗口。它的意义在于：一个站点必须持续检测至少 2τ 的时间，才能确信自己发送的帧没有遭遇冲突。如果在这段时间内没有检测到冲突，那么该站点就成功地捕获了信道，后续不会再发生冲突

### 2.4 Collision Free Protocols

CSMA/CD 只能保证在传输期内无冲突。在信道空闲后，多个站点开始竞争的初期（即竞争期），冲突仍然不可避免

当带宽-延迟积很大时，CSMA/CD 的效率会显著下降，因为冲突窗口 2τ 内能容纳的比特数更多，意味着更短的帧在检测到冲突前可能已经发送完毕，导致冲突无法被检测到，从而需要更高层的协议来纠错，效率更低

为了彻底解决上述问题，提出了 **无冲突协议**。这些协议的目标是从根本上消除冲突，包括竞争期的冲突。它们通过更复杂的协调机制（如轮询、预约或令牌传递）来安排站点的发送顺序，确保在任何时刻最多只有一个站点发送数据

!!! quote ""

    这些无冲突协议目前大多未成为主流，这可能是因为它们的复杂性，或者在传统数据应用场景下，CSMA/CD 的简单性和足够好的性能已能满足需求

    然而，随着对确定性网络和低延迟通信需求的增长，无冲突或确定性调度的思想正在重新获得关注，并可能在未来网络系统中得到应用

!!! tip "A Bit-Map Protocol —— Reservation Protocol"

    先预约，后发送：该协议将时间划分为循环，每个循环包含两个阶段：预约阶段（竞争期）和传输阶段

    1. 预约阶段（位图阶段）：这个阶段被均匀划分为 N 个时槽，其中 N 是网络中的站点总数。每个站点被静态分配一个唯一的时槽编号（从 0 到 N - 1）。如果某个站点有数据要发送，它就在属于自己的那个时槽内发送一个简单的 1 比特作为预约信号；如果该站点没有数据要发送，则其对应的时槽保持空闲。由于每个站点只在属于自己的唯一时槽内进行预约，所以在这个阶段绝对不会发生冲突。经过这 N 个时槽后，每个站点通过监听信道，都获得了一个完全一致的位图，清楚地知道哪些站点想要发送数据
    2. 传输阶段：在预约阶段结束后，所有站点按照站点编号的顺序（例如，从 0 到 N - 1）依次传输它们的数据帧。因为发送顺序是预先确定且所有站点都知道的，所以这个阶段也绝对不会发生冲突。只有那些在预约阶段发出了预约信号（即比特 1）的站点才需要在这个阶段发送数据帧
    3. 循环：当最后一个预约了的站点完成数据帧传输后，一个新的循环开始，再次进入 N 个时槽的预约阶段

    <figure markdown="span">
        ![Img 7](../../../img/computer_network/ch4/network_ch4_img7.png){ width="600" }
    </figure>

!!! tip "Token Passing"

    网络中存在一个特殊的、很短的消息，称为 token。只有持有令牌的站点才被允许发送数据帧。令牌按照一个预定义的逻辑顺序在所有站点间依次传递

    当一个站点从它的上游邻居那里收到令牌时，它检查自己是否有数据要发送。如果有数据：它捕获令牌，然后发送一个或多个数据帧。发送完毕后，它将令牌释放给逻辑序列中的下一个站点。如果没有数据：它立即将令牌传递给下一个站点

    在典型的令牌环网络中，数据帧和令牌沿着同一个方向循环。这就产生了一个问题：数据帧在到达目的站并被拷贝后，如何被从环上移除，以防止它无限循环占用带宽？

    1. 由发送站移除：这是最常见的方式。发送站负责监视环上传回的自己发出的帧。当该帧在环上完整循环一周后，由发送站自己将其从环上移除，并检查目的站是否设置了确认位以判断传输是否成功
    2. 由接收站移除：目的站在接收并拷贝帧后，直接将其从环上移除。这种方式效率稍高，但实现起来更复杂

    实现令牌传递不一定需要物理上的环形布线。令牌传递是一种逻辑访问控制方法（属于数据链路层），它可以运行在多种物理拓扑上。例如，物理环，站点通过电缆实际连接成一个环；物理总线，所有站点连接在一条总线上，但通过软件定义一个逻辑环，令牌按照这个逻辑顺序在总线上的站点间传递

    <figure markdown="span">
        ![Img 8](../../../img/computer_network/ch4/network_ch4_img8.png){ width="600" }
    </figure>

!!! tip "Binary Countdown"

    在位图协议中，预约阶段需要 N 个时槽（N 是站点总数）。每个站点无论是否要发送数据，都固定占用一个时槽的开销。当网络规模很大（站点数 N 很大）时，即使只有少数几个站点要发送数据，也必须等待一个很长的、包含 N 个时槽的预约阶段，效率低下，扩展性差

    二进制倒计数协议是一种分布式、竞争性的仲裁协议。它通过让所有有数据要发送的站点同时广播它们的地址，并在线比较地址高低，来直接选举出当前获得发送权的站点。地址最高的竞争站点赢得信道。

    假设：有四个站点参与竞争，地址分别是 0010 (2), 0100 (4), 1001 (9), 1010 (10)。它们同时开始广播自己的地址，从最高位（MSB）到最低位（LSB）逐位进行

    1. 第 1 位：站点们分别发送 0, 0, 1, 1。信道上的实际信号是这些比特的逻辑或（OR），结果是 1。站点 0010 和 0100 发现自己发送的是 0，但听到信道上却是 1，这意味着存在地址更高的竞争者。它们立即退出竞争并保持沉默。站点 1001 和 1010 发现自己发送的比特与听到的一致（都是 1），因此继续竞争
    2. 第 2 位：剩下的两个站点 1001 和 1010 分别发送 0 和 0。信道上的或结果是 0。两者发送的与听到的一致，都继续
    3. 第 3 位：站点 1001 和 1010 分别发送 0 和 1。信道上的或结果是 1。站点 1001 发现自己发送的是 0，但听到的是 1，因此退出竞争。站点 1010 发送的与听到的一致，赢得信道，获得发送数据的权利

### 2.5 Limited-Contention Protocols

竞争协议（如 ALOHA, CSMA）：

- 优点（低负载）：当网络负载很轻时，站点很少，冲突概率低。站点可以几乎立即尝试发送，因此访问延迟非常低
- 缺点（高负载）：当网络负载很重时，大量站点竞争导致冲突频繁发生。大量时间被浪费在冲突和重传上，信道效率急剧下降

无冲突协议（如位图、令牌）：

- 优点（高负载）：无论负载多高，都通过预约或轮询机制完全避免冲突。信道被有效用于数据传输，信道效率高且稳定
- 缺点（低负载）：即使只有一个站点要发送数据，也可能需要等待一个完整的令牌循环或漫长的预约阶段，导致不必要的延迟

为了克服上述两种协议类型的缺点，同时保留它们的优点，提出了 **有限竞争协议**。其核心思想是：在低负载时表现得像竞争协议（低延迟），在高负载时表现得像无冲突协议（高效率）

传统的竞争协议是对称的，即每个活跃站点在每个竞争时槽内都以相同的概率 $p$ 尝试发送。当有 $k$ 个活跃站点时，在某个时槽内恰好有一个站点成功发送的概率 $A = kp(1-p)^{k-1}$。我们的目标是最大化这个概率 $A$

对于给定的 $k$，存在一个最优的 $p$ 值使得 $A$ 最大。当 $k = 1$ 时，最优 $p = 1$（即直接发送）；当 $k$ 增大时，最优 $p$ 值会减小（即需要降低发送概率以减少冲突）

对称协议的问题在于，当 $k$ 很大时，即使使用最优 $p$，成功概率 $A$ 也会下降

为了突破对称协议的性能限制，有限竞争协议采用了非对称的策略。它动态地将站点分组，使得在任何一个竞争时槽内，参与竞争的站点数量 $k$ 都保持较小，从而可以使用一个较大的 $p$ 值（甚至为 1），以确保高成功概率和低延迟

$p$ 的最佳值为 $\dfrac{1}{k}$，$A_{max} = (\dfrac{k-1}{k})^{k-1}$

一旦活跃竞争者数量 $k$ 超过 5，最大成功概率 $A_{max}$ 就迅速下降并趋近于 36.8%

<figure markdown="span">
    ![Img 9](../../../img/computer_network/ch4/network_ch4_img9.png){ width="600" }
</figure>

提升性能的关键在于限制每个竞争时槽内的活跃站点数。这通过将站点分组来实现

协议将时间划分为一系列竞争时槽。站点被分配到不同的组中（这些组可能重叠）。竞争过程是按组顺序进行的：

1. 时槽 0：只允许组 0 的站点参与竞争。如果该组中恰好有一个站点发送，则它获得信道，传输数据，竞争结束。如果该时槽空闲（组内无站点发送）或发生冲突（组内多个站点发送），则竞争权传递给下一组
2. 时槽 1：只允许组 1 的站点参与竞争。规则同上
3. 此过程持续，直到某个组的某个站点成功获得信道为止

有限竞争协议的目标就是通过精细的分组，使得每一个具体的竞争时槽都只有少数站点在竞争

- 低负载时：有数据要发送的站点很少。如果分组太小、太细，可能会导致需要经历很多个空的竞争时槽才能找到那个唯一的发送站，增加延迟。因此，此时应使用较大的组（甚至所有站点都在一个组里），让它们快速竞争，利用竞争协议低负载下延迟低的优点
- 高负载时：有数据要发送的站点很多。如果使用大组，组内竞争者 k 很大，成功概率会很低，导致多个冲突和重试。因此，此时应使用较小的组（理想情况下每组只有一个站点），这样就变成了无冲突的轮询，利用无冲突协议高负载下效率高的优点

!!! tip "The Adaptive Tree Walk Protocol"

    将所有站点视为一棵二叉树的叶子节点。例如，有 8 个站点，它们就是这棵二叉树的 8 个叶子。树的每个内部节点代表其下所有叶子站点的逻辑分组

    <figure markdown="span">
        ![Img 10](../../../img/computer_network/ch4/network_ch4_img10.png){ width="600" }
    </figure>

    1. 时槽 0：在一次成功的数据传输之后，新的竞争周期开始。第一个竞争时槽（时槽 0）允许所有站点（即根节点 1 下的所有叶子）参与竞争。如果冲突：说明有多个站点（大于等于 2 个）要发送。协议进入树的下一层，以缩小竞争范围
    2. 时槽 1：只允许节点 2 下的站点在时槽 1 内竞争。如果成功：那么在该帧传输完毕后，协议不会回到根节点，而是继续检查节点 2 的兄弟节点，即节点 3 下的站点在下一个时槽竞争。这确保了同一父节点下的所有子组都有机会被检查到；如果再次冲突：说明在节点 2 下仍有多个站点要发送。协议继续深入到更细的分组
    3. 时槽 2：只允许节点 4 下的站点在时槽 2 内竞争
    4. 此过程递归进行，直到某个时槽内只有一个站点竞争（成功发送），或者一个时槽内没有站点竞争（空闲），然后协议会移动到当前节点的兄弟节点继续

    协议不必总是从树根（层级 0）开始竞争

    - 轻负载（q 小）：只有少数几个站点要发送。如果从很深的层级开始，可能会浪费时槽去遍历很多空的节点。从高层级（如根节点）开始可以更快地找到这些分散的发送站
    - 重负载（q 大）：很多站点要发送。如果从根节点开始，几乎必然发生冲突，需要逐层深入，过程缓慢。直接从深层级开始，一开始就在小范围内解决竞争，效率更高

    层级 $i$ 的任何一个节点，其下方包含的站点比例是 $2^{-i}$

    假设有 q 个站点准备发送数据，并且它们均匀分布在整个站点集合中。那么，在层级 i 的任何一个特定节点下，期望的竞争站点数量是：$2^{-i} \times q$

    目标：找到一个起始层级 i，使得在该层级的一个节点下参与竞争的平均站点数恰好为 1。这是效率最高的状态，因为此时成功获取信道的概率最高

    $i = \log_2 q$

### 2.6 Multiple Access with Collision Avoidance

!!! tip "Wireless LAN Protocols"

    与所有节点都连接在同一根电缆上的经典有线以太网不同，无线网络具有其独特的挑战

    Different Coverage Areas（The Hidden Terminal Problem）：在有线网络中，所有站点都能检测到所有其他站点的传输。在无线网络中，由于信号衰减和障碍物，节点的覆盖范围可能不同。例如，节点 A 和节点 C 可能都能与节点 B 通信，但彼此之间可能无法直接侦听到对方。这就导致载波侦听失效：节点 A 在发送前侦听信道，因为听不到节点 C，会认为信道空闲而发送，但此时节点 C 可能正在向节点 B 发送数据，从而在节点 B 处发生冲突。这就是著名的隐藏终端问题

    <figure markdown="span">
        ![Img 11](../../../img/computer_network/ch4/network_ch4_img11.png){ width="600" }
    </figure>

    The Exposed Terminal Problem：当节点 B 正在向节点 A 发送数据时，节点 C 也有数据想要发送给节点 D。节点 C 在发送前进行载波侦听，它检测到了节点 B 正在进行的传输。根据 CSMA 的原则，节点 C 会认为信道繁忙，从而推迟它向节点 D 的发送。然而，从整个网络的角度看，节点 C 的这次发送本应是安全的，不会造成冲突。节点 B 和节点 C 的传输是可以同时进行的。由于节点 C 能够侦听到节点 B，导致它不必要地放弃了发送机会，这就造成了暴露终端问题

    <figure markdown="span">
        ![Img 12](../../../img/computer_network/ch4/network_ch4_img12.png){ width="600" }
    </figure>

    Nodes Cannot Hear while Sending（无法进行冲突检测）：在有线网络中，站点可以同时发送和接收（监听），从而实现 CSMA/CD 中的冲突检测。在无线网络中，一个站点的发射功率远高于其接收灵敏度。如果它在发送信号的同时尝试监听，其强大的发射信号会完全淹没任何可能传入的微弱接收信号。因此，无线站点在发送数据时实际上是聋的，无法检测到正在发生的冲突

    !!! quote ""

        因此，802.11 (Wi-Fi) 不使用 CSMA/CD

MACA 没有尝试去改进不可靠的载波侦听，而是引入了一个主动的 handshake 过程来为数据传输预约信道，从而避免冲突

1. RTS（Request-To-Send）：发送站想要发送数据时，首先向接收站广播一个很短的 RTS 控制帧。这个帧中包含即将发送的数据帧的长度信息。其他收到 RTS 的站点，会在数据帧传输的整个持续时间内对发送站保持静默
2. CTS（Clear-To-Send）：如果接收站成功地收到了 RTS 帧，它就会回复一个同样很短的 CTS 控制帧作为响应。这个 CTS 帧也包含了数据帧的长度信息

    1. 解决隐藏终端：任何能够听到接收站信号的节点（包括发送站不知道的、可能成为隐藏终端的节点），在收到这个 CTS 后，都知道接收站即将接收一个数据帧。因此，它们会在数据帧传输的整个持续时间内保持静默，从而避免了在接收站处发生冲突
    2. 解决暴露终端：只有能听到 CTS 的节点需要保持静默。那些能听到 RTS 但听不到 CTS 的节点，可以推断出自己不在接收站的范围内，自己的发送不会干扰到即将发生的数据传输。因此，它们不需要保持静默，从而缓解了暴露终端问题

3. 数据传输：发送站收到 CTS 后，确信信道已被成功预约，于是开始传输完整的数据帧。此时，由于周围的潜在干扰节点已被 CTS 静默，数据帧成功送达的概率大大提高

RTS 和 CTS 帧本身仍然是广播的，所以它们之间也可能发生冲突。但由于它们非常短，冲突的概率和代价远低于长数据帧的冲突。协议需要定义 RTS 冲突后的退避机制

<figure markdown="span">
    ![Img 13](../../../img/computer_network/ch4/network_ch4_img13.png){ width="600" }
</figure>

## 3 Ethernet

## 4 Wireless LANs (802.11 WiFi)

## 5 Data Link Layer Switching